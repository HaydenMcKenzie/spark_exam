Setup
    SET logger error
    CREATE SparkSession

    READ in files
        CREATE customerData
            from customer_data.csv
        CREATE accountData
            from account_data.csv
        READ addressData
            from address_data.csv


Transform Data - Question 1
    JOIN accountData to customerData by "customerId"

    GROUPBY "customerId", "forename", "surname"
        CREATE Seq of all accountsId with the same "customerId", "forename", "surname".
            ALIAS column "accounts"
        COUNT elements in Seq of "accountId".
            ALIAS column "numberAccounts"
        ADD all numbers from "balance" and round to 2 decimal places.
            ALIAS column "totalBalance"
        AVERAGE all numbers from "balance" and round to 2 decimal places.
            ALIAS column "averageBalance"

    WRITE TO FILE
        Save as a Parquet file
        SHOW new Dataset



Transform Data - Question 2
    READ Parguet file
        from Question 1
    PARSE "address" column in addressData
        from SetUp.scala

    JOIN addressData to Parguet file via "customerId" column
    CREATE customer document
        SELECT addressId, customerId, address, number, road, city, country. Make them a struct
        GROUPBY customerId, forename, surname, accounts
        CREATE new column called "address"
        SELECT customerId, forename, surname, accounts, address.
            Put it in the AddressData schema

    SHOW new Dataset